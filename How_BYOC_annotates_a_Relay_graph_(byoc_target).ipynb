{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aquapapaya/BYOC/blob/main/How_BYOC_annotates_a_Relay_graph_(byoc_target).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pcRLKpMLu2I"
      },
      "source": [
        "# BYOC Demo\n",
        "**Author**: [Kuen-Wey Lin](https://github.com/aquapapaya)\n",
        "\n",
        "We use a simple Relay graph to walkthrough the BYOC workflow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXbWiPPULu2G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7c65b63-cc1b-4bae-bbe1-a51ab784d788"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting apache-tvm\n",
            "  Downloading apache_tvm-0.14.dev273-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (69.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (23.2.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (2.2.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (4.4.2)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (0.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (1.25.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (5.9.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (1.11.4)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (6.3.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (4.10.0)\n",
            "Installing collected packages: apache-tvm\n",
            "Successfully installed apache-tvm-0.14.dev273\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "%%shell\n",
        "# Installs the latest dev build of TVM from pip\n",
        "pip install apache-tvm --pre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BS8WhvdBLu2K"
      },
      "outputs": [],
      "source": [
        "import tvm\n",
        "from tvm import relay\n",
        "import tvm.relay.testing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the entire Relay graph is pretty large, here we use a simple Relay pass to show the total number of operators it has and what they are."
      ],
      "metadata": {
        "id": "v3-atrc2QyBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def profile_graph(func):\n",
        "    class OpProfiler(tvm.relay.ExprVisitor):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.ops = {}\n",
        "\n",
        "        def visit_call(self, call):\n",
        "            op = call.op\n",
        "            if op not in self.ops:\n",
        "                self.ops[op] = 0\n",
        "            self.ops[op] += 1\n",
        "            super().visit_call(call)\n",
        "\n",
        "        def get_byoc_graph_num(self):\n",
        "            cnt = 0\n",
        "            for op in self.ops:\n",
        "                if str(op).find(\"byoc-target\") != -1:\n",
        "                    cnt += 1\n",
        "            return cnt\n",
        "\n",
        "    profiler = OpProfiler()\n",
        "    profiler.visit(func)\n",
        "    print(\"Total number of operators: %d\" % sum(profiler.ops.values()))\n",
        "    print(\"Detail breakdown\")\n",
        "    for op, count in profiler.ops.items():\n",
        "        print(\"\\t%s: %d\" % (op, count))\n",
        "    print(\"byoc-target subgraph #: %d\" % profiler.get_byoc_graph_num())"
      ],
      "metadata": {
        "id": "qFV9NY9xLhzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_9WsjB2Lu2L"
      },
      "source": [
        "Here we demonstrate how BYOC annotates a Relay graph.\n",
        "Let's first define a simple Relay graph with supported and unsupported operators.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sw5iQZPHLu2L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c366d994-d1df-4bfd-9924-e563aad19db5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def @main(%data: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] */, %conv1_1_weight: Tensor[(64, 3, 3, 3), float32] /* ty=Tensor[(64, 3, 3, 3), float32] */, %conv1_1_bias: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %conv2_1_weight: Tensor[(128, 64, 3, 3), float32] /* ty=Tensor[(128, 64, 3, 3), float32] */, %conv2_1_bias: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %conv3_1_weight: Tensor[(256, 128, 3, 3), float32] /* ty=Tensor[(256, 128, 3, 3), float32] */, %conv3_1_bias: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %conv3_2_weight: Tensor[(256, 256, 3, 3), float32] /* ty=Tensor[(256, 256, 3, 3), float32] */, %conv3_2_bias: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %conv4_1_weight: Tensor[(512, 256, 3, 3), float32] /* ty=Tensor[(512, 256, 3, 3), float32] */, %conv4_1_bias: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %conv4_2_weight: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %conv4_2_bias: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %conv5_1_weight: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %conv5_1_bias: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %conv5_2_weight: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %conv5_2_bias: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %fc6_weight: Tensor[(4096, 25088), float32] /* ty=Tensor[(4096, 25088), float32] */, %fc6_bias: Tensor[(4096), float32] /* ty=Tensor[(4096), float32] */, %fc7_weight: Tensor[(4096, 4096), float32] /* ty=Tensor[(4096, 4096), float32] */, %fc7_bias: Tensor[(4096), float32] /* ty=Tensor[(4096), float32] */, %fc8_weight: Tensor[(1000, 4096), float32] /* ty=Tensor[(1000, 4096), float32] */, %fc8_bias: Tensor[(1000), float32] /* ty=Tensor[(1000), float32] */) -> Tensor[(1, 1000), float32] {\n",
            "  %0 = nn.conv2d(%data, %conv1_1_weight, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 224, 224), float32] */;\n",
            "  %1 = nn.bias_add(%0, %conv1_1_bias) /* ty=Tensor[(1, 64, 224, 224), float32] */;\n",
            "  %2 = nn.relu(%1) /* ty=Tensor[(1, 64, 224, 224), float32] */;\n",
            "  %3 = nn.max_pool2d(%2, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
            "  %4 = nn.conv2d(%3, %conv2_1_weight, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 112, 112), float32] */;\n",
            "  %5 = nn.bias_add(%4, %conv2_1_bias) /* ty=Tensor[(1, 128, 112, 112), float32] */;\n",
            "  %6 = nn.relu(%5) /* ty=Tensor[(1, 128, 112, 112), float32] */;\n",
            "  %7 = nn.max_pool2d(%6, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 128, 56, 56), float32] */;\n",
            "  %8 = nn.conv2d(%7, %conv3_1_weight, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %9 = nn.bias_add(%8, %conv3_1_bias) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %10 = nn.relu(%9) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %11 = nn.conv2d(%10, %conv3_2_weight, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %12 = nn.bias_add(%11, %conv3_2_bias) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %13 = nn.relu(%12) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %14 = nn.max_pool2d(%13, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 256, 28, 28), float32] */;\n",
            "  %15 = nn.conv2d(%14, %conv4_1_weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %16 = nn.bias_add(%15, %conv4_1_bias) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %17 = nn.relu(%16) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %18 = nn.conv2d(%17, %conv4_2_weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %19 = nn.bias_add(%18, %conv4_2_bias) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %20 = nn.relu(%19) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %21 = nn.max_pool2d(%20, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %22 = nn.conv2d(%21, %conv5_1_weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %23 = nn.bias_add(%22, %conv5_1_bias) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %24 = nn.relu(%23) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %25 = nn.conv2d(%24, %conv5_2_weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %26 = nn.bias_add(%25, %conv5_2_bias) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %27 = nn.relu(%26) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %28 = nn.max_pool2d(%27, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
            "  %29 = nn.batch_flatten(%28) /* ty=Tensor[(1, 25088), float32] */;\n",
            "  %30 = nn.dense(%29, %fc6_weight, units=4096) /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %31 = nn.bias_add(%30, %fc6_bias, axis=-1) /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %32 = nn.relu(%31) /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %33 = nn.dropout(%32) /* ty=(Tensor[(1, 4096), float32], Tensor[(1, 4096), float32]) */;\n",
            "  %34 = %33.0 /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %35 = nn.dense(%34, %fc7_weight, units=4096) /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %36 = nn.bias_add(%35, %fc7_bias, axis=-1) /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %37 = nn.relu(%36) /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %38 = nn.dropout(%37) /* ty=(Tensor[(1, 4096), float32], Tensor[(1, 4096), float32]) */;\n",
            "  %39 = %38.0 /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %40 = nn.dense(%39, %fc8_weight, units=1000) /* ty=Tensor[(1, 1000), float32] */;\n",
            "  %41 = nn.bias_add(%40, %fc8_bias, axis=-1) /* ty=Tensor[(1, 1000), float32] */;\n",
            "  nn.softmax(%41) /* ty=Tensor[(1, 1000), float32] */\n",
            "}\n",
            "\n",
            "Total number of operators: 41\n",
            "Detail breakdown\n",
            "\tOp(nn.softmax): 1\n",
            "\tOp(nn.bias_add): 11\n",
            "\tOp(nn.dense): 3\n",
            "\tOp(nn.dropout): 2\n",
            "\tOp(nn.relu): 10\n",
            "\tOp(nn.batch_flatten): 1\n",
            "\tOp(nn.max_pool2d): 5\n",
            "\tOp(nn.conv2d): 8\n",
            "byoc-target subgraph #: 0\n"
          ]
        }
      ],
      "source": [
        "# Define the neural network\n",
        "# Get the symbol definition and random weight of a network\n",
        "mod, params = relay.testing.vgg.get_workload(batch_size=1, num_classes=1000,\n",
        "    image_shape=(3, 224, 224), dtype='float32', num_layers=11\n",
        ")\n",
        "print(mod)\n",
        "profile_graph(mod[\"main\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fh_aoRJuLu2L"
      },
      "source": [
        "Then we define the annotation rules.\n",
        "Developers can specify both operator-based and pattern-based annotation rules. Here, we define the single operators `dense` is supported. In addition, we also define two supported patterns `(Conv2D - (Bias) - ReLU)`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SisEgToZLu2L"
      },
      "outputs": [],
      "source": [
        "# Operator-based annotation rules\n",
        "@tvm.ir.register_op_attr(\"nn.dense\", \"target.byoc-target\")\n",
        "def dense(expr):\n",
        "    return True\n",
        "\n",
        "# Pattern-based annotation rules\n",
        "def make_pattern(with_bias=True):\n",
        "    from tvm.relay.dataflow_pattern import is_op, wildcard\n",
        "    data = wildcard()\n",
        "    weight = wildcard()\n",
        "    bias = wildcard()\n",
        "    conv = is_op(\"nn.conv2d\")(data, weight)\n",
        "    if with_bias:\n",
        "        conv_out = is_op(\"nn.bias_add\")(conv, bias)\n",
        "    else:\n",
        "        conv_out = conv\n",
        "    return is_op(\"nn.relu\")(conv_out)\n",
        "\n",
        "conv2d_bias_relu_pat = (\"byoc-target.conv2d_relu_with_bias\", make_pattern(with_bias=True))\n",
        "conv2d_relu_pat = (\"byoc-target.conv2d_relu_wo_bias\", make_pattern(with_bias=False))\n",
        "patterns = [conv2d_bias_relu_pat, conv2d_relu_pat]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S93m1zLpLu2M"
      },
      "source": [
        "Now let's perform pattern-based annotation:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mod2 = relay.transform.MergeComposite(patterns)(mod)\n",
        "print(mod2)\n",
        "profile_graph(mod2[\"main\"])"
      ],
      "metadata": {
        "id": "K6vWlSY0ilrf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b32f8a7-6025-45a4-ef7c-0d11d5d2618e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def @main(%data: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] */, %conv1_1_weight: Tensor[(64, 3, 3, 3), float32] /* ty=Tensor[(64, 3, 3, 3), float32] */, %conv1_1_bias: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %conv2_1_weight: Tensor[(128, 64, 3, 3), float32] /* ty=Tensor[(128, 64, 3, 3), float32] */, %conv2_1_bias: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %conv3_1_weight: Tensor[(256, 128, 3, 3), float32] /* ty=Tensor[(256, 128, 3, 3), float32] */, %conv3_1_bias: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %conv3_2_weight: Tensor[(256, 256, 3, 3), float32] /* ty=Tensor[(256, 256, 3, 3), float32] */, %conv3_2_bias: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %conv4_1_weight: Tensor[(512, 256, 3, 3), float32] /* ty=Tensor[(512, 256, 3, 3), float32] */, %conv4_1_bias: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %conv4_2_weight: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %conv4_2_bias: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %conv5_1_weight: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %conv5_1_bias: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %conv5_2_weight: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %conv5_2_bias: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %fc6_weight: Tensor[(4096, 25088), float32] /* ty=Tensor[(4096, 25088), float32] */, %fc6_bias: Tensor[(4096), float32] /* ty=Tensor[(4096), float32] */, %fc7_weight: Tensor[(4096, 4096), float32] /* ty=Tensor[(4096, 4096), float32] */, %fc7_bias: Tensor[(4096), float32] /* ty=Tensor[(4096), float32] */, %fc8_weight: Tensor[(1000, 4096), float32] /* ty=Tensor[(1000, 4096), float32] */, %fc8_bias: Tensor[(1000), float32] /* ty=Tensor[(1000), float32] */) -> Tensor[(1, 1000), float32] {\n",
            "  %16 = fn (%FunctionVar_7_0: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] */, %FunctionVar_7_1: Tensor[(64, 3, 3, 3), float32] /* ty=Tensor[(64, 3, 3, 3), float32] */, %FunctionVar_7_2: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 64, 224, 224), float32] {\n",
            "    %14 = nn.conv2d(%FunctionVar_7_0, %FunctionVar_7_1, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 224, 224), float32] */;\n",
            "    %15 = nn.bias_add(%14, %FunctionVar_7_2) /* ty=Tensor[(1, 64, 224, 224), float32] */;\n",
            "    nn.relu(%15) /* ty=Tensor[(1, 64, 224, 224), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 3, 224, 224), float32], Tensor[(64, 3, 3, 3), float32], Tensor[(64), float32]) -> Tensor[(1, 64, 224, 224), float32] */;\n",
            "  %17 = %16(%data, %conv1_1_weight, %conv1_1_bias) /* ty=Tensor[(1, 64, 224, 224), float32] */;\n",
            "  %18 = nn.max_pool2d(%17, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
            "  %19 = fn (%FunctionVar_6_0: Tensor[(1, 64, 112, 112), float32] /* ty=Tensor[(1, 64, 112, 112), float32] */, %FunctionVar_6_1: Tensor[(128, 64, 3, 3), float32] /* ty=Tensor[(128, 64, 3, 3), float32] */, %FunctionVar_6_2: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 128, 112, 112), float32] {\n",
            "    %12 = nn.conv2d(%FunctionVar_6_0, %FunctionVar_6_1, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 112, 112), float32] */;\n",
            "    %13 = nn.bias_add(%12, %FunctionVar_6_2) /* ty=Tensor[(1, 128, 112, 112), float32] */;\n",
            "    nn.relu(%13) /* ty=Tensor[(1, 128, 112, 112), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 64, 112, 112), float32], Tensor[(128, 64, 3, 3), float32], Tensor[(128), float32]) -> Tensor[(1, 128, 112, 112), float32] */;\n",
            "  %20 = %19(%18, %conv2_1_weight, %conv2_1_bias) /* ty=Tensor[(1, 128, 112, 112), float32] */;\n",
            "  %21 = nn.max_pool2d(%20, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 128, 56, 56), float32] */;\n",
            "  %22 = fn (%FunctionVar_5_0: Tensor[(1, 128, 56, 56), float32] /* ty=Tensor[(1, 128, 56, 56), float32] */, %FunctionVar_5_1: Tensor[(256, 128, 3, 3), float32] /* ty=Tensor[(256, 128, 3, 3), float32] */, %FunctionVar_5_2: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 256, 56, 56), float32] {\n",
            "    %10 = nn.conv2d(%FunctionVar_5_0, %FunctionVar_5_1, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "    %11 = nn.bias_add(%10, %FunctionVar_5_2) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "    nn.relu(%11) /* ty=Tensor[(1, 256, 56, 56), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 128, 56, 56), float32], Tensor[(256, 128, 3, 3), float32], Tensor[(256), float32]) -> Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %23 = %22(%21, %conv3_1_weight, %conv3_1_bias) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %24 = fn (%FunctionVar_4_0: Tensor[(1, 256, 56, 56), float32] /* ty=Tensor[(1, 256, 56, 56), float32] */, %FunctionVar_4_1: Tensor[(256, 256, 3, 3), float32] /* ty=Tensor[(256, 256, 3, 3), float32] */, %FunctionVar_4_2: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 256, 56, 56), float32] {\n",
            "    %8 = nn.conv2d(%FunctionVar_4_0, %FunctionVar_4_1, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "    %9 = nn.bias_add(%8, %FunctionVar_4_2) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "    nn.relu(%9) /* ty=Tensor[(1, 256, 56, 56), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 256, 56, 56), float32], Tensor[(256, 256, 3, 3), float32], Tensor[(256), float32]) -> Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %25 = %24(%23, %conv3_2_weight, %conv3_2_bias) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %26 = nn.max_pool2d(%25, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 256, 28, 28), float32] */;\n",
            "  %27 = fn (%FunctionVar_3_0: Tensor[(1, 256, 28, 28), float32] /* ty=Tensor[(1, 256, 28, 28), float32] */, %FunctionVar_3_1: Tensor[(512, 256, 3, 3), float32] /* ty=Tensor[(512, 256, 3, 3), float32] */, %FunctionVar_3_2: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 512, 28, 28), float32] {\n",
            "    %6 = nn.conv2d(%FunctionVar_3_0, %FunctionVar_3_1, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "    %7 = nn.bias_add(%6, %FunctionVar_3_2) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "    nn.relu(%7) /* ty=Tensor[(1, 512, 28, 28), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 256, 28, 28), float32], Tensor[(512, 256, 3, 3), float32], Tensor[(512), float32]) -> Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %28 = %27(%26, %conv4_1_weight, %conv4_1_bias) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %29 = fn (%FunctionVar_2_0: Tensor[(1, 512, 28, 28), float32] /* ty=Tensor[(1, 512, 28, 28), float32] */, %FunctionVar_2_1: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %FunctionVar_2_2: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 512, 28, 28), float32] {\n",
            "    %4 = nn.conv2d(%FunctionVar_2_0, %FunctionVar_2_1, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "    %5 = nn.bias_add(%4, %FunctionVar_2_2) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "    nn.relu(%5) /* ty=Tensor[(1, 512, 28, 28), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 512, 28, 28), float32], Tensor[(512, 512, 3, 3), float32], Tensor[(512), float32]) -> Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %30 = %29(%28, %conv4_2_weight, %conv4_2_bias) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %31 = nn.max_pool2d(%30, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %32 = fn (%FunctionVar_1_0: Tensor[(1, 512, 14, 14), float32] /* ty=Tensor[(1, 512, 14, 14), float32] */, %FunctionVar_1_1: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %FunctionVar_1_2: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 512, 14, 14), float32] {\n",
            "    %2 = nn.conv2d(%FunctionVar_1_0, %FunctionVar_1_1, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "    %3 = nn.bias_add(%2, %FunctionVar_1_2) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "    nn.relu(%3) /* ty=Tensor[(1, 512, 14, 14), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 512, 14, 14), float32], Tensor[(512, 512, 3, 3), float32], Tensor[(512), float32]) -> Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %33 = %32(%31, %conv5_1_weight, %conv5_1_bias) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %34 = fn (%FunctionVar_0_0: Tensor[(1, 512, 14, 14), float32] /* ty=Tensor[(1, 512, 14, 14), float32] */, %FunctionVar_0_1: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %FunctionVar_0_2: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 512, 14, 14), float32] {\n",
            "    %0 = nn.conv2d(%FunctionVar_0_0, %FunctionVar_0_1, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "    %1 = nn.bias_add(%0, %FunctionVar_0_2) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "    nn.relu(%1) /* ty=Tensor[(1, 512, 14, 14), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 512, 14, 14), float32], Tensor[(512, 512, 3, 3), float32], Tensor[(512), float32]) -> Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %35 = %34(%33, %conv5_2_weight, %conv5_2_bias) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %36 = nn.max_pool2d(%35, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
            "  %37 = nn.batch_flatten(%36) /* ty=Tensor[(1, 25088), float32] */;\n",
            "  %38 = nn.dense(%37, %fc6_weight, units=4096) /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %39 = nn.bias_add(%38, %fc6_bias, axis=-1) /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %40 = nn.relu(%39) /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %41 = nn.dropout(%40) /* ty=(Tensor[(1, 4096), float32], Tensor[(1, 4096), float32]) */;\n",
            "  %42 = %41.0 /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %43 = nn.dense(%42, %fc7_weight, units=4096) /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %44 = nn.bias_add(%43, %fc7_bias, axis=-1) /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %45 = nn.relu(%44) /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %46 = nn.dropout(%45) /* ty=(Tensor[(1, 4096), float32], Tensor[(1, 4096), float32]) */;\n",
            "  %47 = %46.0 /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %48 = nn.dense(%47, %fc8_weight, units=1000) /* ty=Tensor[(1, 1000), float32] */;\n",
            "  %49 = nn.bias_add(%48, %fc8_bias, axis=-1) /* ty=Tensor[(1, 1000), float32] */;\n",
            "  nn.softmax(%49) /* ty=Tensor[(1, 1000), float32] */\n",
            "}\n",
            "\n",
            "Total number of operators: 49\n",
            "Detail breakdown\n",
            "\tOp(nn.softmax): 1\n",
            "\tOp(nn.bias_add): 11\n",
            "\tOp(nn.dense): 3\n",
            "\tOp(nn.dropout): 2\n",
            "\tOp(nn.relu): 10\n",
            "\tOp(nn.batch_flatten): 1\n",
            "\tOp(nn.max_pool2d): 5\n",
            "\tfn (%FunctionVar_0_0: Tensor[(1, 512, 14, 14), float32] /* ty=Tensor[(1, 512, 14, 14), float32] */, %FunctionVar_0_1: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %FunctionVar_0_2: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 512, 14, 14), float32] {\n",
            "  %0 = nn.conv2d(%FunctionVar_0_0, %FunctionVar_0_1, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %1 = nn.bias_add(%0, %FunctionVar_0_2) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  nn.relu(%1) /* ty=Tensor[(1, 512, 14, 14), float32] */\n",
            "} /* ty=fn (Tensor[(1, 512, 14, 14), float32], Tensor[(512, 512, 3, 3), float32], Tensor[(512), float32]) -> Tensor[(1, 512, 14, 14), float32] */: 1\n",
            "\tOp(nn.conv2d): 8\n",
            "\tfn (%FunctionVar_1_0: Tensor[(1, 512, 14, 14), float32] /* ty=Tensor[(1, 512, 14, 14), float32] */, %FunctionVar_1_1: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %FunctionVar_1_2: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 512, 14, 14), float32] {\n",
            "  %0 = nn.conv2d(%FunctionVar_1_0, %FunctionVar_1_1, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %1 = nn.bias_add(%0, %FunctionVar_1_2) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  nn.relu(%1) /* ty=Tensor[(1, 512, 14, 14), float32] */\n",
            "} /* ty=fn (Tensor[(1, 512, 14, 14), float32], Tensor[(512, 512, 3, 3), float32], Tensor[(512), float32]) -> Tensor[(1, 512, 14, 14), float32] */: 1\n",
            "\tfn (%FunctionVar_2_0: Tensor[(1, 512, 28, 28), float32] /* ty=Tensor[(1, 512, 28, 28), float32] */, %FunctionVar_2_1: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %FunctionVar_2_2: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 512, 28, 28), float32] {\n",
            "  %0 = nn.conv2d(%FunctionVar_2_0, %FunctionVar_2_1, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %1 = nn.bias_add(%0, %FunctionVar_2_2) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "  nn.relu(%1) /* ty=Tensor[(1, 512, 28, 28), float32] */\n",
            "} /* ty=fn (Tensor[(1, 512, 28, 28), float32], Tensor[(512, 512, 3, 3), float32], Tensor[(512), float32]) -> Tensor[(1, 512, 28, 28), float32] */: 1\n",
            "\tfn (%FunctionVar_3_0: Tensor[(1, 256, 28, 28), float32] /* ty=Tensor[(1, 256, 28, 28), float32] */, %FunctionVar_3_1: Tensor[(512, 256, 3, 3), float32] /* ty=Tensor[(512, 256, 3, 3), float32] */, %FunctionVar_3_2: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 512, 28, 28), float32] {\n",
            "  %0 = nn.conv2d(%FunctionVar_3_0, %FunctionVar_3_1, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %1 = nn.bias_add(%0, %FunctionVar_3_2) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "  nn.relu(%1) /* ty=Tensor[(1, 512, 28, 28), float32] */\n",
            "} /* ty=fn (Tensor[(1, 256, 28, 28), float32], Tensor[(512, 256, 3, 3), float32], Tensor[(512), float32]) -> Tensor[(1, 512, 28, 28), float32] */: 1\n",
            "\tfn (%FunctionVar_4_0: Tensor[(1, 256, 56, 56), float32] /* ty=Tensor[(1, 256, 56, 56), float32] */, %FunctionVar_4_1: Tensor[(256, 256, 3, 3), float32] /* ty=Tensor[(256, 256, 3, 3), float32] */, %FunctionVar_4_2: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 256, 56, 56), float32] {\n",
            "  %0 = nn.conv2d(%FunctionVar_4_0, %FunctionVar_4_1, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %1 = nn.bias_add(%0, %FunctionVar_4_2) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "  nn.relu(%1) /* ty=Tensor[(1, 256, 56, 56), float32] */\n",
            "} /* ty=fn (Tensor[(1, 256, 56, 56), float32], Tensor[(256, 256, 3, 3), float32], Tensor[(256), float32]) -> Tensor[(1, 256, 56, 56), float32] */: 1\n",
            "\tfn (%FunctionVar_5_0: Tensor[(1, 128, 56, 56), float32] /* ty=Tensor[(1, 128, 56, 56), float32] */, %FunctionVar_5_1: Tensor[(256, 128, 3, 3), float32] /* ty=Tensor[(256, 128, 3, 3), float32] */, %FunctionVar_5_2: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 256, 56, 56), float32] {\n",
            "  %0 = nn.conv2d(%FunctionVar_5_0, %FunctionVar_5_1, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %1 = nn.bias_add(%0, %FunctionVar_5_2) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "  nn.relu(%1) /* ty=Tensor[(1, 256, 56, 56), float32] */\n",
            "} /* ty=fn (Tensor[(1, 128, 56, 56), float32], Tensor[(256, 128, 3, 3), float32], Tensor[(256), float32]) -> Tensor[(1, 256, 56, 56), float32] */: 1\n",
            "\tfn (%FunctionVar_6_0: Tensor[(1, 64, 112, 112), float32] /* ty=Tensor[(1, 64, 112, 112), float32] */, %FunctionVar_6_1: Tensor[(128, 64, 3, 3), float32] /* ty=Tensor[(128, 64, 3, 3), float32] */, %FunctionVar_6_2: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 128, 112, 112), float32] {\n",
            "  %0 = nn.conv2d(%FunctionVar_6_0, %FunctionVar_6_1, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 112, 112), float32] */;\n",
            "  %1 = nn.bias_add(%0, %FunctionVar_6_2) /* ty=Tensor[(1, 128, 112, 112), float32] */;\n",
            "  nn.relu(%1) /* ty=Tensor[(1, 128, 112, 112), float32] */\n",
            "} /* ty=fn (Tensor[(1, 64, 112, 112), float32], Tensor[(128, 64, 3, 3), float32], Tensor[(128), float32]) -> Tensor[(1, 128, 112, 112), float32] */: 1\n",
            "\tfn (%FunctionVar_7_0: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] */, %FunctionVar_7_1: Tensor[(64, 3, 3, 3), float32] /* ty=Tensor[(64, 3, 3, 3), float32] */, %FunctionVar_7_2: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 64, 224, 224), float32] {\n",
            "  %0 = nn.conv2d(%FunctionVar_7_0, %FunctionVar_7_1, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 224, 224), float32] */;\n",
            "  %1 = nn.bias_add(%0, %FunctionVar_7_2) /* ty=Tensor[(1, 64, 224, 224), float32] */;\n",
            "  nn.relu(%1) /* ty=Tensor[(1, 64, 224, 224), float32] */\n",
            "} /* ty=fn (Tensor[(1, 3, 224, 224), float32], Tensor[(64, 3, 3, 3), float32], Tensor[(64), float32]) -> Tensor[(1, 64, 224, 224), float32] */: 1\n",
            "byoc-target subgraph #: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A composite function has two specialized attributes -- `PartitionedFromPattern` and `Composite`:\n",
        "*   PartitionedFromPattern: Indicate the operators in the function body.\n",
        "*   Composite: Indicate the pattern name we defined.\n",
        "\n",
        "Next, let's continue to apply the operator-based annotation rules:"
      ],
      "metadata": {
        "id": "tQXH6ryAi8NB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mod3 = relay.transform.AnnotateTarget(\"byoc-target\")(mod2)\n",
        "print(mod3)\n",
        "profile_graph(mod3[\"main\"])"
      ],
      "metadata": {
        "id": "8YaCKNNrj4xr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "445470a4-5d14-4359-dbe2-bda263a9f2e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def @main(%data: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] */, %conv1_1_weight: Tensor[(64, 3, 3, 3), float32] /* ty=Tensor[(64, 3, 3, 3), float32] */, %conv1_1_bias: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %conv2_1_weight: Tensor[(128, 64, 3, 3), float32] /* ty=Tensor[(128, 64, 3, 3), float32] */, %conv2_1_bias: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %conv3_1_weight: Tensor[(256, 128, 3, 3), float32] /* ty=Tensor[(256, 128, 3, 3), float32] */, %conv3_1_bias: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %conv3_2_weight: Tensor[(256, 256, 3, 3), float32] /* ty=Tensor[(256, 256, 3, 3), float32] */, %conv3_2_bias: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %conv4_1_weight: Tensor[(512, 256, 3, 3), float32] /* ty=Tensor[(512, 256, 3, 3), float32] */, %conv4_1_bias: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %conv4_2_weight: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %conv4_2_bias: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %conv5_1_weight: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %conv5_1_bias: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %conv5_2_weight: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %conv5_2_bias: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %fc6_weight: Tensor[(4096, 25088), float32] /* ty=Tensor[(4096, 25088), float32] */, %fc6_bias: Tensor[(4096), float32] /* ty=Tensor[(4096), float32] */, %fc7_weight: Tensor[(4096, 4096), float32] /* ty=Tensor[(4096, 4096), float32] */, %fc7_bias: Tensor[(4096), float32] /* ty=Tensor[(4096), float32] */, %fc8_weight: Tensor[(1000, 4096), float32] /* ty=Tensor[(1000, 4096), float32] */, %fc8_bias: Tensor[(1000), float32] /* ty=Tensor[(1000), float32] */) -> Tensor[(1, 1000), float32] {\n",
            "  %16 = annotation.compiler_begin(%data, compiler=\"byoc-target\") /* ty=Tensor[(1, 3, 224, 224), float32] */;\n",
            "  %17 = annotation.compiler_begin(%conv1_1_weight, compiler=\"byoc-target\") /* ty=Tensor[(64, 3, 3, 3), float32] */;\n",
            "  %18 = annotation.compiler_begin(%conv1_1_bias, compiler=\"byoc-target\") /* ty=Tensor[(64), float32] */;\n",
            "  %19 = fn (%FunctionVar_7_0: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] */, %FunctionVar_7_1: Tensor[(64, 3, 3, 3), float32] /* ty=Tensor[(64, 3, 3, 3), float32] */, %FunctionVar_7_2: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 64, 224, 224), float32] {\n",
            "    %14 = nn.conv2d(%FunctionVar_7_0, %FunctionVar_7_1, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 224, 224), float32] */;\n",
            "    %15 = nn.bias_add(%14, %FunctionVar_7_2) /* ty=Tensor[(1, 64, 224, 224), float32] */;\n",
            "    nn.relu(%15) /* ty=Tensor[(1, 64, 224, 224), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 3, 224, 224), float32], Tensor[(64, 3, 3, 3), float32], Tensor[(64), float32]) -> Tensor[(1, 64, 224, 224), float32] */;\n",
            "  %20 = %19(%16, %17, %18) /* ty=Tensor[(1, 64, 224, 224), float32] */;\n",
            "  %21 = annotation.compiler_end(%20, compiler=\"byoc-target\") /* ty=Tensor[(1, 64, 224, 224), float32] */;\n",
            "  %22 = annotation.compiler_begin(%21, compiler=\"default\") /* ty=Tensor[(1, 64, 224, 224), float32] */;\n",
            "  %23 = nn.max_pool2d(%22, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
            "  %24 = annotation.compiler_end(%23, compiler=\"default\") /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
            "  %25 = annotation.compiler_begin(%24, compiler=\"byoc-target\") /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
            "  %26 = annotation.compiler_begin(%conv2_1_weight, compiler=\"byoc-target\") /* ty=Tensor[(128, 64, 3, 3), float32] */;\n",
            "  %27 = annotation.compiler_begin(%conv2_1_bias, compiler=\"byoc-target\") /* ty=Tensor[(128), float32] */;\n",
            "  %28 = fn (%FunctionVar_6_0: Tensor[(1, 64, 112, 112), float32] /* ty=Tensor[(1, 64, 112, 112), float32] */, %FunctionVar_6_1: Tensor[(128, 64, 3, 3), float32] /* ty=Tensor[(128, 64, 3, 3), float32] */, %FunctionVar_6_2: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 128, 112, 112), float32] {\n",
            "    %12 = nn.conv2d(%FunctionVar_6_0, %FunctionVar_6_1, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 112, 112), float32] */;\n",
            "    %13 = nn.bias_add(%12, %FunctionVar_6_2) /* ty=Tensor[(1, 128, 112, 112), float32] */;\n",
            "    nn.relu(%13) /* ty=Tensor[(1, 128, 112, 112), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 64, 112, 112), float32], Tensor[(128, 64, 3, 3), float32], Tensor[(128), float32]) -> Tensor[(1, 128, 112, 112), float32] */;\n",
            "  %29 = %28(%25, %26, %27) /* ty=Tensor[(1, 128, 112, 112), float32] */;\n",
            "  %30 = annotation.compiler_end(%29, compiler=\"byoc-target\") /* ty=Tensor[(1, 128, 112, 112), float32] */;\n",
            "  %31 = annotation.compiler_begin(%30, compiler=\"default\") /* ty=Tensor[(1, 128, 112, 112), float32] */;\n",
            "  %32 = nn.max_pool2d(%31, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 128, 56, 56), float32] */;\n",
            "  %33 = annotation.compiler_end(%32, compiler=\"default\") /* ty=Tensor[(1, 128, 56, 56), float32] */;\n",
            "  %34 = annotation.compiler_begin(%33, compiler=\"byoc-target\") /* ty=Tensor[(1, 128, 56, 56), float32] */;\n",
            "  %35 = annotation.compiler_begin(%conv3_1_weight, compiler=\"byoc-target\") /* ty=Tensor[(256, 128, 3, 3), float32] */;\n",
            "  %36 = annotation.compiler_begin(%conv3_1_bias, compiler=\"byoc-target\") /* ty=Tensor[(256), float32] */;\n",
            "  %37 = fn (%FunctionVar_5_0: Tensor[(1, 128, 56, 56), float32] /* ty=Tensor[(1, 128, 56, 56), float32] */, %FunctionVar_5_1: Tensor[(256, 128, 3, 3), float32] /* ty=Tensor[(256, 128, 3, 3), float32] */, %FunctionVar_5_2: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 256, 56, 56), float32] {\n",
            "    %10 = nn.conv2d(%FunctionVar_5_0, %FunctionVar_5_1, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "    %11 = nn.bias_add(%10, %FunctionVar_5_2) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "    nn.relu(%11) /* ty=Tensor[(1, 256, 56, 56), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 128, 56, 56), float32], Tensor[(256, 128, 3, 3), float32], Tensor[(256), float32]) -> Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %38 = %37(%34, %35, %36) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %39 = annotation.compiler_end(%38, compiler=\"byoc-target\") /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %40 = annotation.compiler_begin(%39, compiler=\"byoc-target\") /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %41 = annotation.compiler_begin(%conv3_2_weight, compiler=\"byoc-target\") /* ty=Tensor[(256, 256, 3, 3), float32] */;\n",
            "  %42 = annotation.compiler_begin(%conv3_2_bias, compiler=\"byoc-target\") /* ty=Tensor[(256), float32] */;\n",
            "  %43 = fn (%FunctionVar_4_0: Tensor[(1, 256, 56, 56), float32] /* ty=Tensor[(1, 256, 56, 56), float32] */, %FunctionVar_4_1: Tensor[(256, 256, 3, 3), float32] /* ty=Tensor[(256, 256, 3, 3), float32] */, %FunctionVar_4_2: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 256, 56, 56), float32] {\n",
            "    %8 = nn.conv2d(%FunctionVar_4_0, %FunctionVar_4_1, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "    %9 = nn.bias_add(%8, %FunctionVar_4_2) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "    nn.relu(%9) /* ty=Tensor[(1, 256, 56, 56), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 256, 56, 56), float32], Tensor[(256, 256, 3, 3), float32], Tensor[(256), float32]) -> Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %44 = %43(%40, %41, %42) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %45 = annotation.compiler_end(%44, compiler=\"byoc-target\") /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %46 = annotation.compiler_begin(%45, compiler=\"default\") /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %47 = nn.max_pool2d(%46, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 256, 28, 28), float32] */;\n",
            "  %48 = annotation.compiler_end(%47, compiler=\"default\") /* ty=Tensor[(1, 256, 28, 28), float32] */;\n",
            "  %49 = annotation.compiler_begin(%48, compiler=\"byoc-target\") /* ty=Tensor[(1, 256, 28, 28), float32] */;\n",
            "  %50 = annotation.compiler_begin(%conv4_1_weight, compiler=\"byoc-target\") /* ty=Tensor[(512, 256, 3, 3), float32] */;\n",
            "  %51 = annotation.compiler_begin(%conv4_1_bias, compiler=\"byoc-target\") /* ty=Tensor[(512), float32] */;\n",
            "  %52 = fn (%FunctionVar_3_0: Tensor[(1, 256, 28, 28), float32] /* ty=Tensor[(1, 256, 28, 28), float32] */, %FunctionVar_3_1: Tensor[(512, 256, 3, 3), float32] /* ty=Tensor[(512, 256, 3, 3), float32] */, %FunctionVar_3_2: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 512, 28, 28), float32] {\n",
            "    %6 = nn.conv2d(%FunctionVar_3_0, %FunctionVar_3_1, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "    %7 = nn.bias_add(%6, %FunctionVar_3_2) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "    nn.relu(%7) /* ty=Tensor[(1, 512, 28, 28), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 256, 28, 28), float32], Tensor[(512, 256, 3, 3), float32], Tensor[(512), float32]) -> Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %53 = %52(%49, %50, %51) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %54 = annotation.compiler_end(%53, compiler=\"byoc-target\") /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %55 = annotation.compiler_begin(%54, compiler=\"byoc-target\") /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %56 = annotation.compiler_begin(%conv4_2_weight, compiler=\"byoc-target\") /* ty=Tensor[(512, 512, 3, 3), float32] */;\n",
            "  %57 = annotation.compiler_begin(%conv4_2_bias, compiler=\"byoc-target\") /* ty=Tensor[(512), float32] */;\n",
            "  %58 = fn (%FunctionVar_2_0: Tensor[(1, 512, 28, 28), float32] /* ty=Tensor[(1, 512, 28, 28), float32] */, %FunctionVar_2_1: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %FunctionVar_2_2: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 512, 28, 28), float32] {\n",
            "    %4 = nn.conv2d(%FunctionVar_2_0, %FunctionVar_2_1, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "    %5 = nn.bias_add(%4, %FunctionVar_2_2) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "    nn.relu(%5) /* ty=Tensor[(1, 512, 28, 28), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 512, 28, 28), float32], Tensor[(512, 512, 3, 3), float32], Tensor[(512), float32]) -> Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %59 = %58(%55, %56, %57) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %60 = annotation.compiler_end(%59, compiler=\"byoc-target\") /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %61 = annotation.compiler_begin(%60, compiler=\"default\") /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %62 = nn.max_pool2d(%61, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %63 = annotation.compiler_end(%62, compiler=\"default\") /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %64 = annotation.compiler_begin(%63, compiler=\"byoc-target\") /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %65 = annotation.compiler_begin(%conv5_1_weight, compiler=\"byoc-target\") /* ty=Tensor[(512, 512, 3, 3), float32] */;\n",
            "  %66 = annotation.compiler_begin(%conv5_1_bias, compiler=\"byoc-target\") /* ty=Tensor[(512), float32] */;\n",
            "  %67 = fn (%FunctionVar_1_0: Tensor[(1, 512, 14, 14), float32] /* ty=Tensor[(1, 512, 14, 14), float32] */, %FunctionVar_1_1: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %FunctionVar_1_2: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 512, 14, 14), float32] {\n",
            "    %2 = nn.conv2d(%FunctionVar_1_0, %FunctionVar_1_1, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "    %3 = nn.bias_add(%2, %FunctionVar_1_2) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "    nn.relu(%3) /* ty=Tensor[(1, 512, 14, 14), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 512, 14, 14), float32], Tensor[(512, 512, 3, 3), float32], Tensor[(512), float32]) -> Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %68 = %67(%64, %65, %66) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %69 = annotation.compiler_end(%68, compiler=\"byoc-target\") /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %70 = annotation.compiler_begin(%69, compiler=\"byoc-target\") /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %71 = annotation.compiler_begin(%conv5_2_weight, compiler=\"byoc-target\") /* ty=Tensor[(512, 512, 3, 3), float32] */;\n",
            "  %72 = annotation.compiler_begin(%conv5_2_bias, compiler=\"byoc-target\") /* ty=Tensor[(512), float32] */;\n",
            "  %73 = fn (%FunctionVar_0_0: Tensor[(1, 512, 14, 14), float32] /* ty=Tensor[(1, 512, 14, 14), float32] */, %FunctionVar_0_1: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %FunctionVar_0_2: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 512, 14, 14), float32] {\n",
            "    %0 = nn.conv2d(%FunctionVar_0_0, %FunctionVar_0_1, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "    %1 = nn.bias_add(%0, %FunctionVar_0_2) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "    nn.relu(%1) /* ty=Tensor[(1, 512, 14, 14), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 512, 14, 14), float32], Tensor[(512, 512, 3, 3), float32], Tensor[(512), float32]) -> Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %74 = %73(%70, %71, %72) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %75 = annotation.compiler_end(%74, compiler=\"byoc-target\") /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %76 = annotation.compiler_begin(%75, compiler=\"default\") /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %77 = nn.max_pool2d(%76, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
            "  %78 = annotation.compiler_end(%77, compiler=\"default\") /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
            "  %79 = annotation.compiler_begin(%78, compiler=\"default\") /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
            "  %80 = nn.batch_flatten(%79) /* ty=Tensor[(1, 25088), float32] */;\n",
            "  %81 = annotation.compiler_end(%80, compiler=\"default\") /* ty=Tensor[(1, 25088), float32] */;\n",
            "  %82 = annotation.compiler_begin(%81, compiler=\"byoc-target\") /* ty=Tensor[(1, 25088), float32] */;\n",
            "  %83 = annotation.compiler_begin(%fc6_weight, compiler=\"byoc-target\") /* ty=Tensor[(4096, 25088), float32] */;\n",
            "  %84 = nn.dense(%82, %83, units=4096) /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %85 = annotation.compiler_end(%84, compiler=\"byoc-target\") /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %86 = annotation.compiler_begin(%85, compiler=\"default\") /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %87 = annotation.compiler_begin(%fc6_bias, compiler=\"default\") /* ty=Tensor[(4096), float32] */;\n",
            "  %88 = nn.bias_add(%86, %87, axis=-1) /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %89 = annotation.compiler_end(%88, compiler=\"default\") /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %90 = annotation.compiler_begin(%89, compiler=\"default\") /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %91 = nn.relu(%90) /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %92 = annotation.compiler_end(%91, compiler=\"default\") /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %93 = annotation.compiler_begin(%92, compiler=\"default\") /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %94 = nn.dropout(%93) /* ty=(Tensor[(1, 4096), float32], Tensor[(1, 4096), float32]) */;\n",
            "  %95 = annotation.compiler_end(%94, compiler=\"default\") /* ty=(Tensor[(1, 4096), float32], Tensor[(1, 4096), float32]) */;\n",
            "  %96 = annotation.compiler_begin(%95, compiler=\"default\") /* ty=(Tensor[(1, 4096), float32], Tensor[(1, 4096), float32]) */;\n",
            "  %97 = %96.0 /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %98 = annotation.compiler_end(%97, compiler=\"default\") /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %99 = annotation.compiler_begin(%98, compiler=\"byoc-target\") /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %100 = annotation.compiler_begin(%fc7_weight, compiler=\"byoc-target\") /* ty=Tensor[(4096, 4096), float32] */;\n",
            "  %101 = nn.dense(%99, %100, units=4096) /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %102 = annotation.compiler_end(%101, compiler=\"byoc-target\") /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %103 = annotation.compiler_begin(%102, compiler=\"default\") /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %104 = annotation.compiler_begin(%fc7_bias, compiler=\"default\") /* ty=Tensor[(4096), float32] */;\n",
            "  %105 = nn.bias_add(%103, %104, axis=-1) /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %106 = annotation.compiler_end(%105, compiler=\"default\") /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %107 = annotation.compiler_begin(%106, compiler=\"default\") /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %108 = nn.relu(%107) /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %109 = annotation.compiler_end(%108, compiler=\"default\") /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %110 = annotation.compiler_begin(%109, compiler=\"default\") /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %111 = nn.dropout(%110) /* ty=(Tensor[(1, 4096), float32], Tensor[(1, 4096), float32]) */;\n",
            "  %112 = annotation.compiler_end(%111, compiler=\"default\") /* ty=(Tensor[(1, 4096), float32], Tensor[(1, 4096), float32]) */;\n",
            "  %113 = annotation.compiler_begin(%112, compiler=\"default\") /* ty=(Tensor[(1, 4096), float32], Tensor[(1, 4096), float32]) */;\n",
            "  %114 = %113.0 /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %115 = annotation.compiler_end(%114, compiler=\"default\") /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %116 = annotation.compiler_begin(%115, compiler=\"byoc-target\") /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %117 = annotation.compiler_begin(%fc8_weight, compiler=\"byoc-target\") /* ty=Tensor[(1000, 4096), float32] */;\n",
            "  %118 = nn.dense(%116, %117, units=1000) /* ty=Tensor[(1, 1000), float32] */;\n",
            "  %119 = annotation.compiler_end(%118, compiler=\"byoc-target\") /* ty=Tensor[(1, 1000), float32] */;\n",
            "  %120 = annotation.compiler_begin(%119, compiler=\"default\") /* ty=Tensor[(1, 1000), float32] */;\n",
            "  %121 = annotation.compiler_begin(%fc8_bias, compiler=\"default\") /* ty=Tensor[(1000), float32] */;\n",
            "  %122 = nn.bias_add(%120, %121, axis=-1) /* ty=Tensor[(1, 1000), float32] */;\n",
            "  %123 = annotation.compiler_end(%122, compiler=\"default\") /* ty=Tensor[(1, 1000), float32] */;\n",
            "  %124 = annotation.compiler_begin(%123, compiler=\"default\") /* ty=Tensor[(1, 1000), float32] */;\n",
            "  %125 = nn.softmax(%124) /* ty=Tensor[(1, 1000), float32] */;\n",
            "  annotation.compiler_end(%125, compiler=\"default\") /* ty=Tensor[(1, 1000), float32] */\n",
            "}\n",
            "\n",
            "Total number of operators: 125\n",
            "Detail breakdown\n",
            "\tOp(annotation.compiler_end): 27\n",
            "\tOp(nn.softmax): 1\n",
            "\tOp(annotation.compiler_begin): 49\n",
            "\tOp(nn.bias_add): 11\n",
            "\tOp(nn.dense): 3\n",
            "\tOp(nn.dropout): 2\n",
            "\tOp(nn.relu): 10\n",
            "\tOp(nn.batch_flatten): 1\n",
            "\tOp(nn.max_pool2d): 5\n",
            "\tfn (%FunctionVar_0_0: Tensor[(1, 512, 14, 14), float32] /* ty=Tensor[(1, 512, 14, 14), float32] */, %FunctionVar_0_1: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %FunctionVar_0_2: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 512, 14, 14), float32] {\n",
            "  %0 = nn.conv2d(%FunctionVar_0_0, %FunctionVar_0_1, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %1 = nn.bias_add(%0, %FunctionVar_0_2) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  nn.relu(%1) /* ty=Tensor[(1, 512, 14, 14), float32] */\n",
            "} /* ty=fn (Tensor[(1, 512, 14, 14), float32], Tensor[(512, 512, 3, 3), float32], Tensor[(512), float32]) -> Tensor[(1, 512, 14, 14), float32] */: 1\n",
            "\tOp(nn.conv2d): 8\n",
            "\tfn (%FunctionVar_1_0: Tensor[(1, 512, 14, 14), float32] /* ty=Tensor[(1, 512, 14, 14), float32] */, %FunctionVar_1_1: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %FunctionVar_1_2: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 512, 14, 14), float32] {\n",
            "  %0 = nn.conv2d(%FunctionVar_1_0, %FunctionVar_1_1, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %1 = nn.bias_add(%0, %FunctionVar_1_2) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  nn.relu(%1) /* ty=Tensor[(1, 512, 14, 14), float32] */\n",
            "} /* ty=fn (Tensor[(1, 512, 14, 14), float32], Tensor[(512, 512, 3, 3), float32], Tensor[(512), float32]) -> Tensor[(1, 512, 14, 14), float32] */: 1\n",
            "\tfn (%FunctionVar_2_0: Tensor[(1, 512, 28, 28), float32] /* ty=Tensor[(1, 512, 28, 28), float32] */, %FunctionVar_2_1: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %FunctionVar_2_2: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 512, 28, 28), float32] {\n",
            "  %0 = nn.conv2d(%FunctionVar_2_0, %FunctionVar_2_1, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %1 = nn.bias_add(%0, %FunctionVar_2_2) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "  nn.relu(%1) /* ty=Tensor[(1, 512, 28, 28), float32] */\n",
            "} /* ty=fn (Tensor[(1, 512, 28, 28), float32], Tensor[(512, 512, 3, 3), float32], Tensor[(512), float32]) -> Tensor[(1, 512, 28, 28), float32] */: 1\n",
            "\tfn (%FunctionVar_3_0: Tensor[(1, 256, 28, 28), float32] /* ty=Tensor[(1, 256, 28, 28), float32] */, %FunctionVar_3_1: Tensor[(512, 256, 3, 3), float32] /* ty=Tensor[(512, 256, 3, 3), float32] */, %FunctionVar_3_2: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 512, 28, 28), float32] {\n",
            "  %0 = nn.conv2d(%FunctionVar_3_0, %FunctionVar_3_1, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %1 = nn.bias_add(%0, %FunctionVar_3_2) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "  nn.relu(%1) /* ty=Tensor[(1, 512, 28, 28), float32] */\n",
            "} /* ty=fn (Tensor[(1, 256, 28, 28), float32], Tensor[(512, 256, 3, 3), float32], Tensor[(512), float32]) -> Tensor[(1, 512, 28, 28), float32] */: 1\n",
            "\tfn (%FunctionVar_4_0: Tensor[(1, 256, 56, 56), float32] /* ty=Tensor[(1, 256, 56, 56), float32] */, %FunctionVar_4_1: Tensor[(256, 256, 3, 3), float32] /* ty=Tensor[(256, 256, 3, 3), float32] */, %FunctionVar_4_2: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 256, 56, 56), float32] {\n",
            "  %0 = nn.conv2d(%FunctionVar_4_0, %FunctionVar_4_1, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %1 = nn.bias_add(%0, %FunctionVar_4_2) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "  nn.relu(%1) /* ty=Tensor[(1, 256, 56, 56), float32] */\n",
            "} /* ty=fn (Tensor[(1, 256, 56, 56), float32], Tensor[(256, 256, 3, 3), float32], Tensor[(256), float32]) -> Tensor[(1, 256, 56, 56), float32] */: 1\n",
            "\tfn (%FunctionVar_5_0: Tensor[(1, 128, 56, 56), float32] /* ty=Tensor[(1, 128, 56, 56), float32] */, %FunctionVar_5_1: Tensor[(256, 128, 3, 3), float32] /* ty=Tensor[(256, 128, 3, 3), float32] */, %FunctionVar_5_2: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 256, 56, 56), float32] {\n",
            "  %0 = nn.conv2d(%FunctionVar_5_0, %FunctionVar_5_1, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %1 = nn.bias_add(%0, %FunctionVar_5_2) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "  nn.relu(%1) /* ty=Tensor[(1, 256, 56, 56), float32] */\n",
            "} /* ty=fn (Tensor[(1, 128, 56, 56), float32], Tensor[(256, 128, 3, 3), float32], Tensor[(256), float32]) -> Tensor[(1, 256, 56, 56), float32] */: 1\n",
            "\tfn (%FunctionVar_6_0: Tensor[(1, 64, 112, 112), float32] /* ty=Tensor[(1, 64, 112, 112), float32] */, %FunctionVar_6_1: Tensor[(128, 64, 3, 3), float32] /* ty=Tensor[(128, 64, 3, 3), float32] */, %FunctionVar_6_2: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 128, 112, 112), float32] {\n",
            "  %0 = nn.conv2d(%FunctionVar_6_0, %FunctionVar_6_1, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 112, 112), float32] */;\n",
            "  %1 = nn.bias_add(%0, %FunctionVar_6_2) /* ty=Tensor[(1, 128, 112, 112), float32] */;\n",
            "  nn.relu(%1) /* ty=Tensor[(1, 128, 112, 112), float32] */\n",
            "} /* ty=fn (Tensor[(1, 64, 112, 112), float32], Tensor[(128, 64, 3, 3), float32], Tensor[(128), float32]) -> Tensor[(1, 128, 112, 112), float32] */: 1\n",
            "\tfn (%FunctionVar_7_0: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] */, %FunctionVar_7_1: Tensor[(64, 3, 3, 3), float32] /* ty=Tensor[(64, 3, 3, 3), float32] */, %FunctionVar_7_2: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 64, 224, 224), float32] {\n",
            "  %0 = nn.conv2d(%FunctionVar_7_0, %FunctionVar_7_1, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 224, 224), float32] */;\n",
            "  %1 = nn.bias_add(%0, %FunctionVar_7_2) /* ty=Tensor[(1, 64, 224, 224), float32] */;\n",
            "  nn.relu(%1) /* ty=Tensor[(1, 64, 224, 224), float32] */\n",
            "} /* ty=fn (Tensor[(1, 3, 224, 224), float32], Tensor[(64, 3, 3, 3), float32], Tensor[(64), float32]) -> Tensor[(1, 64, 224, 224), float32] */: 1\n",
            "byoc-target subgraph #: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mod4 = relay.transform.MergeCompilerRegions()(mod3)\n",
        "print(mod4)\n",
        "profile_graph(mod4[\"main\"])"
      ],
      "metadata": {
        "id": "n9C2bBQOlRZE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a16ec476-e338-4596-c487-299d127eef2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def @main(%data: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] */, %conv1_1_weight: Tensor[(64, 3, 3, 3), float32] /* ty=Tensor[(64, 3, 3, 3), float32] */, %conv1_1_bias: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %conv2_1_weight: Tensor[(128, 64, 3, 3), float32] /* ty=Tensor[(128, 64, 3, 3), float32] */, %conv2_1_bias: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %conv3_1_weight: Tensor[(256, 128, 3, 3), float32] /* ty=Tensor[(256, 128, 3, 3), float32] */, %conv3_1_bias: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %conv3_2_weight: Tensor[(256, 256, 3, 3), float32] /* ty=Tensor[(256, 256, 3, 3), float32] */, %conv3_2_bias: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %conv4_1_weight: Tensor[(512, 256, 3, 3), float32] /* ty=Tensor[(512, 256, 3, 3), float32] */, %conv4_1_bias: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %conv4_2_weight: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %conv4_2_bias: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %conv5_1_weight: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %conv5_1_bias: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %conv5_2_weight: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %conv5_2_bias: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %fc6_weight: Tensor[(4096, 25088), float32] /* ty=Tensor[(4096, 25088), float32] */, %fc6_bias: Tensor[(4096), float32] /* ty=Tensor[(4096), float32] */, %fc7_weight: Tensor[(4096, 4096), float32] /* ty=Tensor[(4096, 4096), float32] */, %fc7_bias: Tensor[(4096), float32] /* ty=Tensor[(4096), float32] */, %fc8_weight: Tensor[(1000, 4096), float32] /* ty=Tensor[(1000, 4096), float32] */, %fc8_bias: Tensor[(1000), float32] /* ty=Tensor[(1000), float32] */) -> Tensor[(1, 1000), float32] {\n",
            "  %16 = annotation.compiler_begin(%data, compiler=\"byoc-target\") /* ty=Tensor[(1, 3, 224, 224), float32] */;\n",
            "  %17 = annotation.compiler_begin(%conv1_1_weight, compiler=\"byoc-target\") /* ty=Tensor[(64, 3, 3, 3), float32] */;\n",
            "  %18 = annotation.compiler_begin(%conv1_1_bias, compiler=\"byoc-target\") /* ty=Tensor[(64), float32] */;\n",
            "  %19 = fn (%FunctionVar_7_0: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] */, %FunctionVar_7_1: Tensor[(64, 3, 3, 3), float32] /* ty=Tensor[(64, 3, 3, 3), float32] */, %FunctionVar_7_2: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 64, 224, 224), float32] {\n",
            "    %14 = nn.conv2d(%FunctionVar_7_0, %FunctionVar_7_1, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 224, 224), float32] */;\n",
            "    %15 = nn.bias_add(%14, %FunctionVar_7_2) /* ty=Tensor[(1, 64, 224, 224), float32] */;\n",
            "    nn.relu(%15) /* ty=Tensor[(1, 64, 224, 224), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 3, 224, 224), float32], Tensor[(64, 3, 3, 3), float32], Tensor[(64), float32]) -> Tensor[(1, 64, 224, 224), float32] */;\n",
            "  %20 = %19(%16, %17, %18) /* ty=Tensor[(1, 64, 224, 224), float32] */;\n",
            "  %21 = annotation.compiler_end(%20, compiler=\"byoc-target\") /* ty=Tensor[(1, 64, 224, 224), float32] */;\n",
            "  %22 = annotation.compiler_begin(%21, compiler=\"default\") /* ty=Tensor[(1, 64, 224, 224), float32] */;\n",
            "  %23 = nn.max_pool2d(%22, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
            "  %24 = annotation.compiler_end(%23, compiler=\"default\") /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
            "  %25 = annotation.compiler_begin(%24, compiler=\"byoc-target\") /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
            "  %26 = annotation.compiler_begin(%conv2_1_weight, compiler=\"byoc-target\") /* ty=Tensor[(128, 64, 3, 3), float32] */;\n",
            "  %27 = annotation.compiler_begin(%conv2_1_bias, compiler=\"byoc-target\") /* ty=Tensor[(128), float32] */;\n",
            "  %28 = fn (%FunctionVar_6_0: Tensor[(1, 64, 112, 112), float32] /* ty=Tensor[(1, 64, 112, 112), float32] */, %FunctionVar_6_1: Tensor[(128, 64, 3, 3), float32] /* ty=Tensor[(128, 64, 3, 3), float32] */, %FunctionVar_6_2: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 128, 112, 112), float32] {\n",
            "    %12 = nn.conv2d(%FunctionVar_6_0, %FunctionVar_6_1, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 112, 112), float32] */;\n",
            "    %13 = nn.bias_add(%12, %FunctionVar_6_2) /* ty=Tensor[(1, 128, 112, 112), float32] */;\n",
            "    nn.relu(%13) /* ty=Tensor[(1, 128, 112, 112), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 64, 112, 112), float32], Tensor[(128, 64, 3, 3), float32], Tensor[(128), float32]) -> Tensor[(1, 128, 112, 112), float32] */;\n",
            "  %29 = %28(%25, %26, %27) /* ty=Tensor[(1, 128, 112, 112), float32] */;\n",
            "  %30 = annotation.compiler_end(%29, compiler=\"byoc-target\") /* ty=Tensor[(1, 128, 112, 112), float32] */;\n",
            "  %31 = annotation.compiler_begin(%30, compiler=\"default\") /* ty=Tensor[(1, 128, 112, 112), float32] */;\n",
            "  %32 = nn.max_pool2d(%31, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 128, 56, 56), float32] */;\n",
            "  %33 = annotation.compiler_end(%32, compiler=\"default\") /* ty=Tensor[(1, 128, 56, 56), float32] */;\n",
            "  %34 = annotation.compiler_begin(%33, compiler=\"byoc-target\") /* ty=Tensor[(1, 128, 56, 56), float32] */;\n",
            "  %35 = annotation.compiler_begin(%conv3_1_weight, compiler=\"byoc-target\") /* ty=Tensor[(256, 128, 3, 3), float32] */;\n",
            "  %36 = annotation.compiler_begin(%conv3_1_bias, compiler=\"byoc-target\") /* ty=Tensor[(256), float32] */;\n",
            "  %37 = fn (%FunctionVar_5_0: Tensor[(1, 128, 56, 56), float32] /* ty=Tensor[(1, 128, 56, 56), float32] */, %FunctionVar_5_1: Tensor[(256, 128, 3, 3), float32] /* ty=Tensor[(256, 128, 3, 3), float32] */, %FunctionVar_5_2: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 256, 56, 56), float32] {\n",
            "    %10 = nn.conv2d(%FunctionVar_5_0, %FunctionVar_5_1, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "    %11 = nn.bias_add(%10, %FunctionVar_5_2) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "    nn.relu(%11) /* ty=Tensor[(1, 256, 56, 56), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 128, 56, 56), float32], Tensor[(256, 128, 3, 3), float32], Tensor[(256), float32]) -> Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %38 = %37(%34, %35, %36) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %39 = annotation.compiler_begin(%conv3_2_weight, compiler=\"byoc-target\") /* ty=Tensor[(256, 256, 3, 3), float32] */;\n",
            "  %40 = annotation.compiler_begin(%conv3_2_bias, compiler=\"byoc-target\") /* ty=Tensor[(256), float32] */;\n",
            "  %41 = fn (%FunctionVar_4_0: Tensor[(1, 256, 56, 56), float32] /* ty=Tensor[(1, 256, 56, 56), float32] */, %FunctionVar_4_1: Tensor[(256, 256, 3, 3), float32] /* ty=Tensor[(256, 256, 3, 3), float32] */, %FunctionVar_4_2: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 256, 56, 56), float32] {\n",
            "    %8 = nn.conv2d(%FunctionVar_4_0, %FunctionVar_4_1, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "    %9 = nn.bias_add(%8, %FunctionVar_4_2) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "    nn.relu(%9) /* ty=Tensor[(1, 256, 56, 56), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 256, 56, 56), float32], Tensor[(256, 256, 3, 3), float32], Tensor[(256), float32]) -> Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %42 = %41(%38, %39, %40) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %43 = annotation.compiler_end(%42, compiler=\"byoc-target\") /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %44 = annotation.compiler_begin(%43, compiler=\"default\") /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %45 = nn.max_pool2d(%44, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 256, 28, 28), float32] */;\n",
            "  %46 = annotation.compiler_end(%45, compiler=\"default\") /* ty=Tensor[(1, 256, 28, 28), float32] */;\n",
            "  %47 = annotation.compiler_begin(%46, compiler=\"byoc-target\") /* ty=Tensor[(1, 256, 28, 28), float32] */;\n",
            "  %48 = annotation.compiler_begin(%conv4_1_weight, compiler=\"byoc-target\") /* ty=Tensor[(512, 256, 3, 3), float32] */;\n",
            "  %49 = annotation.compiler_begin(%conv4_1_bias, compiler=\"byoc-target\") /* ty=Tensor[(512), float32] */;\n",
            "  %50 = fn (%FunctionVar_3_0: Tensor[(1, 256, 28, 28), float32] /* ty=Tensor[(1, 256, 28, 28), float32] */, %FunctionVar_3_1: Tensor[(512, 256, 3, 3), float32] /* ty=Tensor[(512, 256, 3, 3), float32] */, %FunctionVar_3_2: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 512, 28, 28), float32] {\n",
            "    %6 = nn.conv2d(%FunctionVar_3_0, %FunctionVar_3_1, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "    %7 = nn.bias_add(%6, %FunctionVar_3_2) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "    nn.relu(%7) /* ty=Tensor[(1, 512, 28, 28), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 256, 28, 28), float32], Tensor[(512, 256, 3, 3), float32], Tensor[(512), float32]) -> Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %51 = %50(%47, %48, %49) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %52 = annotation.compiler_begin(%conv4_2_weight, compiler=\"byoc-target\") /* ty=Tensor[(512, 512, 3, 3), float32] */;\n",
            "  %53 = annotation.compiler_begin(%conv4_2_bias, compiler=\"byoc-target\") /* ty=Tensor[(512), float32] */;\n",
            "  %54 = fn (%FunctionVar_2_0: Tensor[(1, 512, 28, 28), float32] /* ty=Tensor[(1, 512, 28, 28), float32] */, %FunctionVar_2_1: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %FunctionVar_2_2: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 512, 28, 28), float32] {\n",
            "    %4 = nn.conv2d(%FunctionVar_2_0, %FunctionVar_2_1, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "    %5 = nn.bias_add(%4, %FunctionVar_2_2) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "    nn.relu(%5) /* ty=Tensor[(1, 512, 28, 28), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 512, 28, 28), float32], Tensor[(512, 512, 3, 3), float32], Tensor[(512), float32]) -> Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %55 = %54(%51, %52, %53) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %56 = annotation.compiler_end(%55, compiler=\"byoc-target\") /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %57 = annotation.compiler_begin(%56, compiler=\"default\") /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %58 = nn.max_pool2d(%57, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %59 = annotation.compiler_end(%58, compiler=\"default\") /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %60 = annotation.compiler_begin(%59, compiler=\"byoc-target\") /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %61 = annotation.compiler_begin(%conv5_1_weight, compiler=\"byoc-target\") /* ty=Tensor[(512, 512, 3, 3), float32] */;\n",
            "  %62 = annotation.compiler_begin(%conv5_1_bias, compiler=\"byoc-target\") /* ty=Tensor[(512), float32] */;\n",
            "  %63 = fn (%FunctionVar_1_0: Tensor[(1, 512, 14, 14), float32] /* ty=Tensor[(1, 512, 14, 14), float32] */, %FunctionVar_1_1: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %FunctionVar_1_2: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 512, 14, 14), float32] {\n",
            "    %2 = nn.conv2d(%FunctionVar_1_0, %FunctionVar_1_1, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "    %3 = nn.bias_add(%2, %FunctionVar_1_2) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "    nn.relu(%3) /* ty=Tensor[(1, 512, 14, 14), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 512, 14, 14), float32], Tensor[(512, 512, 3, 3), float32], Tensor[(512), float32]) -> Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %64 = %63(%60, %61, %62) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %65 = annotation.compiler_begin(%conv5_2_weight, compiler=\"byoc-target\") /* ty=Tensor[(512, 512, 3, 3), float32] */;\n",
            "  %66 = annotation.compiler_begin(%conv5_2_bias, compiler=\"byoc-target\") /* ty=Tensor[(512), float32] */;\n",
            "  %67 = fn (%FunctionVar_0_0: Tensor[(1, 512, 14, 14), float32] /* ty=Tensor[(1, 512, 14, 14), float32] */, %FunctionVar_0_1: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %FunctionVar_0_2: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 512, 14, 14), float32] {\n",
            "    %0 = nn.conv2d(%FunctionVar_0_0, %FunctionVar_0_1, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "    %1 = nn.bias_add(%0, %FunctionVar_0_2) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "    nn.relu(%1) /* ty=Tensor[(1, 512, 14, 14), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 512, 14, 14), float32], Tensor[(512, 512, 3, 3), float32], Tensor[(512), float32]) -> Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %68 = %67(%64, %65, %66) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %69 = annotation.compiler_end(%68, compiler=\"byoc-target\") /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %70 = annotation.compiler_begin(%69, compiler=\"default\") /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %71 = nn.max_pool2d(%70, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
            "  %72 = nn.batch_flatten(%71) /* ty=Tensor[(1, 25088), float32] */;\n",
            "  %73 = annotation.compiler_end(%72, compiler=\"default\") /* ty=Tensor[(1, 25088), float32] */;\n",
            "  %74 = annotation.compiler_begin(%73, compiler=\"byoc-target\") /* ty=Tensor[(1, 25088), float32] */;\n",
            "  %75 = annotation.compiler_begin(%fc6_weight, compiler=\"byoc-target\") /* ty=Tensor[(4096, 25088), float32] */;\n",
            "  %76 = nn.dense(%74, %75, units=4096) /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %77 = annotation.compiler_end(%76, compiler=\"byoc-target\") /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %78 = annotation.compiler_begin(%77, compiler=\"default\") /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %79 = annotation.compiler_begin(%fc6_bias, compiler=\"default\") /* ty=Tensor[(4096), float32] */;\n",
            "  %80 = nn.bias_add(%78, %79, axis=-1) /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %81 = nn.relu(%80) /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %82 = nn.dropout(%81) /* ty=(Tensor[(1, 4096), float32], Tensor[(1, 4096), float32]) */;\n",
            "  %83 = %82.0 /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %84 = annotation.compiler_end(%83, compiler=\"default\") /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %85 = annotation.compiler_begin(%84, compiler=\"byoc-target\") /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %86 = annotation.compiler_begin(%fc7_weight, compiler=\"byoc-target\") /* ty=Tensor[(4096, 4096), float32] */;\n",
            "  %87 = nn.dense(%85, %86, units=4096) /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %88 = annotation.compiler_end(%87, compiler=\"byoc-target\") /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %89 = annotation.compiler_begin(%88, compiler=\"default\") /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %90 = annotation.compiler_begin(%fc7_bias, compiler=\"default\") /* ty=Tensor[(4096), float32] */;\n",
            "  %91 = nn.bias_add(%89, %90, axis=-1) /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %92 = nn.relu(%91) /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %93 = nn.dropout(%92) /* ty=(Tensor[(1, 4096), float32], Tensor[(1, 4096), float32]) */;\n",
            "  %94 = %93.0 /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %95 = annotation.compiler_end(%94, compiler=\"default\") /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %96 = annotation.compiler_begin(%95, compiler=\"byoc-target\") /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %97 = annotation.compiler_begin(%fc8_weight, compiler=\"byoc-target\") /* ty=Tensor[(1000, 4096), float32] */;\n",
            "  %98 = nn.dense(%96, %97, units=1000) /* ty=Tensor[(1, 1000), float32] */;\n",
            "  %99 = annotation.compiler_end(%98, compiler=\"byoc-target\") /* ty=Tensor[(1, 1000), float32] */;\n",
            "  %100 = annotation.compiler_begin(%99, compiler=\"default\") /* ty=Tensor[(1, 1000), float32] */;\n",
            "  %101 = annotation.compiler_begin(%fc8_bias, compiler=\"default\") /* ty=Tensor[(1000), float32] */;\n",
            "  %102 = nn.bias_add(%100, %101, axis=-1) /* ty=Tensor[(1, 1000), float32] */;\n",
            "  %103 = nn.softmax(%102) /* ty=Tensor[(1, 1000), float32] */;\n",
            "  annotation.compiler_end(%103, compiler=\"default\") /* ty=Tensor[(1, 1000), float32] */\n",
            "}\n",
            "\n",
            "Total number of operators: 103\n",
            "Detail breakdown\n",
            "\tOp(annotation.compiler_end): 16\n",
            "\tOp(nn.softmax): 1\n",
            "\tOp(nn.bias_add): 11\n",
            "\tOp(annotation.compiler_begin): 38\n",
            "\tOp(nn.dense): 3\n",
            "\tOp(nn.dropout): 2\n",
            "\tOp(nn.relu): 10\n",
            "\tOp(nn.batch_flatten): 1\n",
            "\tOp(nn.max_pool2d): 5\n",
            "\tfn (%FunctionVar_0_0: Tensor[(1, 512, 14, 14), float32] /* ty=Tensor[(1, 512, 14, 14), float32] */, %FunctionVar_0_1: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %FunctionVar_0_2: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 512, 14, 14), float32] {\n",
            "  %0 = nn.conv2d(%FunctionVar_0_0, %FunctionVar_0_1, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %1 = nn.bias_add(%0, %FunctionVar_0_2) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  nn.relu(%1) /* ty=Tensor[(1, 512, 14, 14), float32] */\n",
            "} /* ty=fn (Tensor[(1, 512, 14, 14), float32], Tensor[(512, 512, 3, 3), float32], Tensor[(512), float32]) -> Tensor[(1, 512, 14, 14), float32] */: 1\n",
            "\tOp(nn.conv2d): 8\n",
            "\tfn (%FunctionVar_1_0: Tensor[(1, 512, 14, 14), float32] /* ty=Tensor[(1, 512, 14, 14), float32] */, %FunctionVar_1_1: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %FunctionVar_1_2: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 512, 14, 14), float32] {\n",
            "  %0 = nn.conv2d(%FunctionVar_1_0, %FunctionVar_1_1, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %1 = nn.bias_add(%0, %FunctionVar_1_2) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  nn.relu(%1) /* ty=Tensor[(1, 512, 14, 14), float32] */\n",
            "} /* ty=fn (Tensor[(1, 512, 14, 14), float32], Tensor[(512, 512, 3, 3), float32], Tensor[(512), float32]) -> Tensor[(1, 512, 14, 14), float32] */: 1\n",
            "\tfn (%FunctionVar_2_0: Tensor[(1, 512, 28, 28), float32] /* ty=Tensor[(1, 512, 28, 28), float32] */, %FunctionVar_2_1: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %FunctionVar_2_2: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 512, 28, 28), float32] {\n",
            "  %0 = nn.conv2d(%FunctionVar_2_0, %FunctionVar_2_1, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %1 = nn.bias_add(%0, %FunctionVar_2_2) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "  nn.relu(%1) /* ty=Tensor[(1, 512, 28, 28), float32] */\n",
            "} /* ty=fn (Tensor[(1, 512, 28, 28), float32], Tensor[(512, 512, 3, 3), float32], Tensor[(512), float32]) -> Tensor[(1, 512, 28, 28), float32] */: 1\n",
            "\tfn (%FunctionVar_3_0: Tensor[(1, 256, 28, 28), float32] /* ty=Tensor[(1, 256, 28, 28), float32] */, %FunctionVar_3_1: Tensor[(512, 256, 3, 3), float32] /* ty=Tensor[(512, 256, 3, 3), float32] */, %FunctionVar_3_2: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 512, 28, 28), float32] {\n",
            "  %0 = nn.conv2d(%FunctionVar_3_0, %FunctionVar_3_1, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %1 = nn.bias_add(%0, %FunctionVar_3_2) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "  nn.relu(%1) /* ty=Tensor[(1, 512, 28, 28), float32] */\n",
            "} /* ty=fn (Tensor[(1, 256, 28, 28), float32], Tensor[(512, 256, 3, 3), float32], Tensor[(512), float32]) -> Tensor[(1, 512, 28, 28), float32] */: 1\n",
            "\tfn (%FunctionVar_4_0: Tensor[(1, 256, 56, 56), float32] /* ty=Tensor[(1, 256, 56, 56), float32] */, %FunctionVar_4_1: Tensor[(256, 256, 3, 3), float32] /* ty=Tensor[(256, 256, 3, 3), float32] */, %FunctionVar_4_2: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 256, 56, 56), float32] {\n",
            "  %0 = nn.conv2d(%FunctionVar_4_0, %FunctionVar_4_1, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %1 = nn.bias_add(%0, %FunctionVar_4_2) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "  nn.relu(%1) /* ty=Tensor[(1, 256, 56, 56), float32] */\n",
            "} /* ty=fn (Tensor[(1, 256, 56, 56), float32], Tensor[(256, 256, 3, 3), float32], Tensor[(256), float32]) -> Tensor[(1, 256, 56, 56), float32] */: 1\n",
            "\tfn (%FunctionVar_5_0: Tensor[(1, 128, 56, 56), float32] /* ty=Tensor[(1, 128, 56, 56), float32] */, %FunctionVar_5_1: Tensor[(256, 128, 3, 3), float32] /* ty=Tensor[(256, 128, 3, 3), float32] */, %FunctionVar_5_2: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 256, 56, 56), float32] {\n",
            "  %0 = nn.conv2d(%FunctionVar_5_0, %FunctionVar_5_1, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %1 = nn.bias_add(%0, %FunctionVar_5_2) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "  nn.relu(%1) /* ty=Tensor[(1, 256, 56, 56), float32] */\n",
            "} /* ty=fn (Tensor[(1, 128, 56, 56), float32], Tensor[(256, 128, 3, 3), float32], Tensor[(256), float32]) -> Tensor[(1, 256, 56, 56), float32] */: 1\n",
            "\tfn (%FunctionVar_6_0: Tensor[(1, 64, 112, 112), float32] /* ty=Tensor[(1, 64, 112, 112), float32] */, %FunctionVar_6_1: Tensor[(128, 64, 3, 3), float32] /* ty=Tensor[(128, 64, 3, 3), float32] */, %FunctionVar_6_2: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 128, 112, 112), float32] {\n",
            "  %0 = nn.conv2d(%FunctionVar_6_0, %FunctionVar_6_1, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 112, 112), float32] */;\n",
            "  %1 = nn.bias_add(%0, %FunctionVar_6_2) /* ty=Tensor[(1, 128, 112, 112), float32] */;\n",
            "  nn.relu(%1) /* ty=Tensor[(1, 128, 112, 112), float32] */\n",
            "} /* ty=fn (Tensor[(1, 64, 112, 112), float32], Tensor[(128, 64, 3, 3), float32], Tensor[(128), float32]) -> Tensor[(1, 128, 112, 112), float32] */: 1\n",
            "\tfn (%FunctionVar_7_0: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] */, %FunctionVar_7_1: Tensor[(64, 3, 3, 3), float32] /* ty=Tensor[(64, 3, 3, 3), float32] */, %FunctionVar_7_2: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 64, 224, 224), float32] {\n",
            "  %0 = nn.conv2d(%FunctionVar_7_0, %FunctionVar_7_1, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 224, 224), float32] */;\n",
            "  %1 = nn.bias_add(%0, %FunctionVar_7_2) /* ty=Tensor[(1, 64, 224, 224), float32] */;\n",
            "  nn.relu(%1) /* ty=Tensor[(1, 64, 224, 224), float32] */\n",
            "} /* ty=fn (Tensor[(1, 3, 224, 224), float32], Tensor[(64, 3, 3, 3), float32], Tensor[(64), float32]) -> Tensor[(1, 64, 224, 224), float32] */: 1\n",
            "byoc-target subgraph #: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Almost all nodes in the graph are annotated with `compiler_begin` and `compiler_end` nodes. `compiler_*` nodes has an attribute `compiler` to indicate which target should this node go. In this example, it can be `default` or `byoc-target`.\n",
        "\n",
        "Composite function calls are also annotated with `compiler=byoc-target`, indicating that this entire function can be offloaded.\n",
        "\n",
        "We use the pass, `MergeCompilerRegion`, to merge them so that we can minimize the number of subgraphs.\n",
        "\n",
        "Finally, let's partition this graph:"
      ],
      "metadata": {
        "id": "XvjHEZzSBOOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mod5 = relay.transform.PartitionGraph()(mod4)\n",
        "print(mod5)"
      ],
      "metadata": {
        "id": "nL1d4RxNDnfL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4d4b639-cb76-49be-d81b-c131b8f32916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def @main(%data: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] */, %conv1_1_weight: Tensor[(64, 3, 3, 3), float32] /* ty=Tensor[(64, 3, 3, 3), float32] */, %conv1_1_bias: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %conv2_1_weight: Tensor[(128, 64, 3, 3), float32] /* ty=Tensor[(128, 64, 3, 3), float32] */, %conv2_1_bias: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %conv3_1_weight: Tensor[(256, 128, 3, 3), float32] /* ty=Tensor[(256, 128, 3, 3), float32] */, %conv3_1_bias: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %conv3_2_weight: Tensor[(256, 256, 3, 3), float32] /* ty=Tensor[(256, 256, 3, 3), float32] */, %conv3_2_bias: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %conv4_1_weight: Tensor[(512, 256, 3, 3), float32] /* ty=Tensor[(512, 256, 3, 3), float32] */, %conv4_1_bias: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %conv4_2_weight: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %conv4_2_bias: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %conv5_1_weight: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %conv5_1_bias: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %conv5_2_weight: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %conv5_2_bias: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %fc6_weight: Tensor[(4096, 25088), float32] /* ty=Tensor[(4096, 25088), float32] */, %fc6_bias: Tensor[(4096), float32] /* ty=Tensor[(4096), float32] */, %fc7_weight: Tensor[(4096, 4096), float32] /* ty=Tensor[(4096, 4096), float32] */, %fc7_bias: Tensor[(4096), float32] /* ty=Tensor[(4096), float32] */, %fc8_weight: Tensor[(1000, 4096), float32] /* ty=Tensor[(1000, 4096), float32] */, %fc8_bias: Tensor[(1000), float32] /* ty=Tensor[(1000), float32] */) -> Tensor[(1, 1000), float32] {\n",
            "  %0 = @tvmgen_default_byoc_target_main_0(%data, %conv1_1_weight, %conv1_1_bias) /* ty=Tensor[(1, 64, 224, 224), float32] */;\n",
            "  %1 = nn.max_pool2d(%0, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
            "  %2 = @tvmgen_default_byoc_target_main_3(%1, %conv2_1_weight, %conv2_1_bias) /* ty=Tensor[(1, 128, 112, 112), float32] */;\n",
            "  %3 = nn.max_pool2d(%2, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 128, 56, 56), float32] */;\n",
            "  %4 = @tvmgen_default_byoc_target_main_6(%3, %conv3_1_weight, %conv3_1_bias, %conv3_2_weight, %conv3_2_bias) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %5 = nn.max_pool2d(%4, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 256, 28, 28), float32] */;\n",
            "  %6 = @tvmgen_default_byoc_target_main_11(%5, %conv4_1_weight, %conv4_1_bias, %conv4_2_weight, %conv4_2_bias) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %7 = nn.max_pool2d(%6, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %8 = @tvmgen_default_byoc_target_main_16(%7, %conv5_1_weight, %conv5_1_bias, %conv5_2_weight, %conv5_2_bias) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %9 = nn.max_pool2d(%8, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
            "  %10 = nn.batch_flatten(%9) /* ty=Tensor[(1, 25088), float32] */;\n",
            "  %11 = @tvmgen_default_byoc_target_main_21(%10, %fc6_weight) /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %12 = nn.bias_add(%11, %fc6_bias, axis=-1) /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %13 = nn.relu(%12) /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %14 = nn.dropout(%13) /* ty=(Tensor[(1, 4096), float32], Tensor[(1, 4096), float32]) */;\n",
            "  %15 = %14.0 /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %16 = @tvmgen_default_byoc_target_main_23(%15, %fc7_weight) /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %17 = nn.bias_add(%16, %fc7_bias, axis=-1) /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %18 = nn.relu(%17) /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %19 = nn.dropout(%18) /* ty=(Tensor[(1, 4096), float32], Tensor[(1, 4096), float32]) */;\n",
            "  %20 = %19.0 /* ty=Tensor[(1, 4096), float32] */;\n",
            "  %21 = @tvmgen_default_byoc_target_main_25(%20, %fc8_weight) /* ty=Tensor[(1, 1000), float32] */;\n",
            "  %22 = nn.bias_add(%21, %fc8_bias, axis=-1) /* ty=Tensor[(1, 1000), float32] */;\n",
            "  nn.softmax(%22) /* ty=Tensor[(1, 1000), float32] */\n",
            "}\n",
            "\n",
            "def @tvmgen_default_byoc_target_main_0(%byoc-target_0_i0: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] */, %byoc-target_0_i1: Tensor[(64, 3, 3, 3), float32] /* ty=Tensor[(64, 3, 3, 3), float32] */, %byoc-target_0_i2: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, Compiler=\"byoc-target\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_byoc_target_main_0\") -> Tensor[(1, 64, 224, 224), float32] {\n",
            "  %25 = fn (%FunctionVar_7_0: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] */, %FunctionVar_7_1: Tensor[(64, 3, 3, 3), float32] /* ty=Tensor[(64, 3, 3, 3), float32] */, %FunctionVar_7_2: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 64, 224, 224), float32] {\n",
            "    %23 = nn.conv2d(%FunctionVar_7_0, %FunctionVar_7_1, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 224, 224), float32] */;\n",
            "    %24 = nn.bias_add(%23, %FunctionVar_7_2) /* ty=Tensor[(1, 64, 224, 224), float32] */;\n",
            "    nn.relu(%24) /* ty=Tensor[(1, 64, 224, 224), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 3, 224, 224), float32], Tensor[(64, 3, 3, 3), float32], Tensor[(64), float32]) -> Tensor[(1, 64, 224, 224), float32] */;\n",
            "  %25(%byoc-target_0_i0, %byoc-target_0_i1, %byoc-target_0_i2) /* ty=Tensor[(1, 64, 224, 224), float32] */\n",
            "}\n",
            "\n",
            "def @tvmgen_default_byoc_target_main_11(%byoc-target_11_i0: Tensor[(1, 256, 28, 28), float32] /* ty=Tensor[(1, 256, 28, 28), float32] */, %byoc-target_11_i1: Tensor[(512, 256, 3, 3), float32] /* ty=Tensor[(512, 256, 3, 3), float32] */, %byoc-target_11_i2: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %byoc-target_11_i3: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %byoc-target_11_i4: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, Compiler=\"byoc-target\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_byoc_target_main_11\") -> Tensor[(1, 512, 28, 28), float32] {\n",
            "  %30 = fn (%FunctionVar_3_0: Tensor[(1, 256, 28, 28), float32] /* ty=Tensor[(1, 256, 28, 28), float32] */, %FunctionVar_3_1: Tensor[(512, 256, 3, 3), float32] /* ty=Tensor[(512, 256, 3, 3), float32] */, %FunctionVar_3_2: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 512, 28, 28), float32] {\n",
            "    %28 = nn.conv2d(%FunctionVar_3_0, %FunctionVar_3_1, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "    %29 = nn.bias_add(%28, %FunctionVar_3_2) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "    nn.relu(%29) /* ty=Tensor[(1, 512, 28, 28), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 256, 28, 28), float32], Tensor[(512, 256, 3, 3), float32], Tensor[(512), float32]) -> Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %31 = %30(%byoc-target_11_i0, %byoc-target_11_i1, %byoc-target_11_i2) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %32 = fn (%FunctionVar_2_0: Tensor[(1, 512, 28, 28), float32] /* ty=Tensor[(1, 512, 28, 28), float32] */, %FunctionVar_2_1: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %FunctionVar_2_2: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 512, 28, 28), float32] {\n",
            "    %26 = nn.conv2d(%FunctionVar_2_0, %FunctionVar_2_1, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "    %27 = nn.bias_add(%26, %FunctionVar_2_2) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
            "    nn.relu(%27) /* ty=Tensor[(1, 512, 28, 28), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 512, 28, 28), float32], Tensor[(512, 512, 3, 3), float32], Tensor[(512), float32]) -> Tensor[(1, 512, 28, 28), float32] */;\n",
            "  %32(%31, %byoc-target_11_i3, %byoc-target_11_i4) /* ty=Tensor[(1, 512, 28, 28), float32] */\n",
            "}\n",
            "\n",
            "def @tvmgen_default_byoc_target_main_16(%byoc-target_16_i0: Tensor[(1, 512, 14, 14), float32] /* ty=Tensor[(1, 512, 14, 14), float32] */, %byoc-target_16_i1: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %byoc-target_16_i2: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %byoc-target_16_i3: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %byoc-target_16_i4: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, Compiler=\"byoc-target\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_byoc_target_main_16\") -> Tensor[(1, 512, 14, 14), float32] {\n",
            "  %37 = fn (%FunctionVar_1_0: Tensor[(1, 512, 14, 14), float32] /* ty=Tensor[(1, 512, 14, 14), float32] */, %FunctionVar_1_1: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %FunctionVar_1_2: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 512, 14, 14), float32] {\n",
            "    %35 = nn.conv2d(%FunctionVar_1_0, %FunctionVar_1_1, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "    %36 = nn.bias_add(%35, %FunctionVar_1_2) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "    nn.relu(%36) /* ty=Tensor[(1, 512, 14, 14), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 512, 14, 14), float32], Tensor[(512, 512, 3, 3), float32], Tensor[(512), float32]) -> Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %38 = %37(%byoc-target_16_i0, %byoc-target_16_i1, %byoc-target_16_i2) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %39 = fn (%FunctionVar_0_0: Tensor[(1, 512, 14, 14), float32] /* ty=Tensor[(1, 512, 14, 14), float32] */, %FunctionVar_0_1: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %FunctionVar_0_2: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 512, 14, 14), float32] {\n",
            "    %33 = nn.conv2d(%FunctionVar_0_0, %FunctionVar_0_1, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "    %34 = nn.bias_add(%33, %FunctionVar_0_2) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
            "    nn.relu(%34) /* ty=Tensor[(1, 512, 14, 14), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 512, 14, 14), float32], Tensor[(512, 512, 3, 3), float32], Tensor[(512), float32]) -> Tensor[(1, 512, 14, 14), float32] */;\n",
            "  %39(%38, %byoc-target_16_i3, %byoc-target_16_i4) /* ty=Tensor[(1, 512, 14, 14), float32] */\n",
            "}\n",
            "\n",
            "def @tvmgen_default_byoc_target_main_21(%byoc-target_21_i0: Tensor[(1, 25088), float32] /* ty=Tensor[(1, 25088), float32] */, %byoc-target_21_i1: Tensor[(4096, 25088), float32] /* ty=Tensor[(4096, 25088), float32] */, Compiler=\"byoc-target\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_byoc_target_main_21\") -> Tensor[(1, 4096), float32] {\n",
            "  nn.dense(%byoc-target_21_i0, %byoc-target_21_i1, units=4096) /* ty=Tensor[(1, 4096), float32] */\n",
            "}\n",
            "\n",
            "def @tvmgen_default_byoc_target_main_23(%byoc-target_23_i0: Tensor[(1, 4096), float32] /* ty=Tensor[(1, 4096), float32] */, %byoc-target_23_i1: Tensor[(4096, 4096), float32] /* ty=Tensor[(4096, 4096), float32] */, Compiler=\"byoc-target\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_byoc_target_main_23\") -> Tensor[(1, 4096), float32] {\n",
            "  nn.dense(%byoc-target_23_i0, %byoc-target_23_i1, units=4096) /* ty=Tensor[(1, 4096), float32] */\n",
            "}\n",
            "\n",
            "def @tvmgen_default_byoc_target_main_25(%byoc-target_25_i0: Tensor[(1, 4096), float32] /* ty=Tensor[(1, 4096), float32] */, %byoc-target_25_i1: Tensor[(1000, 4096), float32] /* ty=Tensor[(1000, 4096), float32] */, Compiler=\"byoc-target\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_byoc_target_main_25\") -> Tensor[(1, 1000), float32] {\n",
            "  nn.dense(%byoc-target_25_i0, %byoc-target_25_i1, units=1000) /* ty=Tensor[(1, 1000), float32] */\n",
            "}\n",
            "\n",
            "def @tvmgen_default_byoc_target_main_3(%byoc-target_3_i0: Tensor[(1, 64, 112, 112), float32] /* ty=Tensor[(1, 64, 112, 112), float32] */, %byoc-target_3_i1: Tensor[(128, 64, 3, 3), float32] /* ty=Tensor[(128, 64, 3, 3), float32] */, %byoc-target_3_i2: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, Compiler=\"byoc-target\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_byoc_target_main_3\") -> Tensor[(1, 128, 112, 112), float32] {\n",
            "  %42 = fn (%FunctionVar_6_0: Tensor[(1, 64, 112, 112), float32] /* ty=Tensor[(1, 64, 112, 112), float32] */, %FunctionVar_6_1: Tensor[(128, 64, 3, 3), float32] /* ty=Tensor[(128, 64, 3, 3), float32] */, %FunctionVar_6_2: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 128, 112, 112), float32] {\n",
            "    %40 = nn.conv2d(%FunctionVar_6_0, %FunctionVar_6_1, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 112, 112), float32] */;\n",
            "    %41 = nn.bias_add(%40, %FunctionVar_6_2) /* ty=Tensor[(1, 128, 112, 112), float32] */;\n",
            "    nn.relu(%41) /* ty=Tensor[(1, 128, 112, 112), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 64, 112, 112), float32], Tensor[(128, 64, 3, 3), float32], Tensor[(128), float32]) -> Tensor[(1, 128, 112, 112), float32] */;\n",
            "  %42(%byoc-target_3_i0, %byoc-target_3_i1, %byoc-target_3_i2) /* ty=Tensor[(1, 128, 112, 112), float32] */\n",
            "}\n",
            "\n",
            "def @tvmgen_default_byoc_target_main_6(%byoc-target_6_i0: Tensor[(1, 128, 56, 56), float32] /* ty=Tensor[(1, 128, 56, 56), float32] */, %byoc-target_6_i1: Tensor[(256, 128, 3, 3), float32] /* ty=Tensor[(256, 128, 3, 3), float32] */, %byoc-target_6_i2: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %byoc-target_6_i3: Tensor[(256, 256, 3, 3), float32] /* ty=Tensor[(256, 256, 3, 3), float32] */, %byoc-target_6_i4: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, Compiler=\"byoc-target\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_byoc_target_main_6\") -> Tensor[(1, 256, 56, 56), float32] {\n",
            "  %47 = fn (%FunctionVar_5_0: Tensor[(1, 128, 56, 56), float32] /* ty=Tensor[(1, 128, 56, 56), float32] */, %FunctionVar_5_1: Tensor[(256, 128, 3, 3), float32] /* ty=Tensor[(256, 128, 3, 3), float32] */, %FunctionVar_5_2: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 256, 56, 56), float32] {\n",
            "    %45 = nn.conv2d(%FunctionVar_5_0, %FunctionVar_5_1, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "    %46 = nn.bias_add(%45, %FunctionVar_5_2) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "    nn.relu(%46) /* ty=Tensor[(1, 256, 56, 56), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 128, 56, 56), float32], Tensor[(256, 128, 3, 3), float32], Tensor[(256), float32]) -> Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %48 = %47(%byoc-target_6_i0, %byoc-target_6_i1, %byoc-target_6_i2) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %49 = fn (%FunctionVar_4_0: Tensor[(1, 256, 56, 56), float32] /* ty=Tensor[(1, 256, 56, 56), float32] */, %FunctionVar_4_1: Tensor[(256, 256, 3, 3), float32] /* ty=Tensor[(256, 256, 3, 3), float32] */, %FunctionVar_4_2: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 256, 56, 56), float32] {\n",
            "    %43 = nn.conv2d(%FunctionVar_4_0, %FunctionVar_4_1, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "    %44 = nn.bias_add(%43, %FunctionVar_4_2) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
            "    nn.relu(%44) /* ty=Tensor[(1, 256, 56, 56), float32] */\n",
            "  } /* ty=fn (Tensor[(1, 256, 56, 56), float32], Tensor[(256, 256, 3, 3), float32], Tensor[(256), float32]) -> Tensor[(1, 256, 56, 56), float32] */;\n",
            "  %49(%48, %byoc-target_6_i3, %byoc-target_6_i4) /* ty=Tensor[(1, 256, 56, 56), float32] */\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that 8 subgraphs have been partitioned for `byoc-target`.\n",
        "\n",
        "\n",
        "\n",
        "1.   @tvmgen_default_byoc_target_main_0\n",
        "2.   @tvmgen_default_byoc_target_main_3\n",
        "3.   @tvmgen_default_byoc_target_main_6\n",
        "4.   @tvmgen_default_byoc_target_main_11\n",
        "5.   @tvmgen_default_byoc_target_main_16\n",
        "6.   @tvmgen_default_byoc_target_main_21\n",
        "7.   @tvmgen_default_byoc_target_main_23\n",
        "8.   @tvmgen_default_byoc_target_main_25\n",
        "\n",
        "Each partitioned function will be sent to the `byoc-target` codegen for code generation.\n",
        "\n",
        "As a result, you can imagine that the customized codegen only needs to consider the subgraphs without worrying about rest parts of the graph.\n",
        "\n"
      ],
      "metadata": {
        "id": "hVPoX64LGmiA"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}